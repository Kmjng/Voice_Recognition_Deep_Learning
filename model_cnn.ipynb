{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kmjng/Voice_Recognition_Deep_Learning/blob/main/model_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3VYIlJ2IaSf2",
        "outputId": "05846dd0-3537-48b4-f13f-6a5646d26e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2XtFb_M-pSqm",
        "outputId": "c133a0d1-f180-4622-e387-c7b912dc1363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import glob\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoWcYi68Qf4V"
      },
      "source": [
        "# 음성데이터 세션 나누기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "81NdJdv6K8FJ",
        "outputId": "33503ae2-82bb-483b-d9ae-63f2fcd4f203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/AI/AI.vampire - ROSÉ (ai cover).wav', \"/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/AI/AI.Taylor Swift IA - we can't be friends (wait for your love) (artificial intelligence version).wav\", '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/AI/AI.Passenger - LET HER GO (ED SHEERAN - A.I COVER LYRICS).wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/AI/AI.Jungkook - Off My Face (AI Cover).wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/AI/AI.Copy of Standing Next to You - AI theWeeknd.wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/AI/AI.Copy of Jungkook - Die For You (AI cover).wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/AI/AI.CHIQUITA Ai Cover “ 2002” (Anne Marie).wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/AI/AI.Avril Lavigne - August (Taylor Swift Cover).wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/AI/AI.Avril Lavigne - 3am (Halsey AI Cover).wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/원본/ori.Taylor Swift – august.wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/원본/ori.Passenger - Let Her Go.wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/원본/ori.Olivia Rodrigo - vampire.wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/원본/ori.Justin Bieber - Off My Face.wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/원본/ori.Copy of The Weeknd - Die For You (Audio).wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/원본/ori.Copy of Jungkook Standing Next To You Lyrics.wav', \"/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/원본/ori.Ariana Grande - we can't be friends (wait for your love).wav\", '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/원본/ori.Anne Marie - 2002.wav', '/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/원본/ori.3am.wav']\n"
          ]
        }
      ],
      "source": [
        "AI_root = glob.glob(r\"/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/AI/*\")\n",
        "ori_root = glob.glob(r\"/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/원본/*\")\n",
        "X_path = AI_root + ori_root\n",
        "print(X_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "MDq63isHTnAN"
      },
      "outputs": [],
      "source": [
        "pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "kzgm5Rj5V4Nx"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#음원 구간별 추출\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "for a in X_path:\n",
        "  # wav 파일 로드\n",
        "  audio = AudioSegment.from_wav(a)\n",
        "\n",
        "  # 분할 간격 설정 (밀리초 단위)\n",
        "  interval = 10 * 1000  # 10초 = 10,000 밀리초\n",
        "  step = 5 * 1000  # 5초 = 5,000 밀리초\n",
        "\n",
        "  # 전체 길이\n",
        "  length = len(audio) #밀리초로 환산됨\n",
        "\n",
        "\n",
        "  # 저장할 디렉토리 설정\n",
        "  output_dir = r'/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/save'\n",
        "\n",
        "  # 분할 및 저장\n",
        "  for i in range(0, length, step):\n",
        "      start_time = i  # 시작 시간 (밀리초 단위)\n",
        "      end_time = i + interval  # 종료 시간 (밀리초 단위)\n",
        "      split_audio = audio[start_time:end_time]\n",
        "      start_sec = start_time // 1000  # 시작 시간 (초 단위)\n",
        "      end_sec = end_time // 1000  # 종료 시간 (초 단위)\n",
        "      filename = os.path.join(output_dir, f\"output_{start_sec}-{end_sec}_{os.path.basename(a)}.wav\")\n",
        "      split_audio.export(filename, format=\"wav\")\n",
        "      print(f\"Saved {filename}\")\n",
        "\n",
        "  print(\"분할 완료\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm5aHBWkQYJX"
      },
      "source": [
        "# 모델링 시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cKeEvDwqVBu2"
      },
      "outputs": [],
      "source": [
        "#구간별 추출한 데이터 경로 저장\n",
        "X_path_new = glob.glob(r\"/gdrive/MyDrive/빅데이터 45기_파이널 프로젝트/음원데이터/save/*\")\n",
        "print(len(X_path_new))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "6muONVxvMY5T"
      },
      "outputs": [],
      "source": [
        "import ntpath # 특정 경로에서 파일들을 가져오는 라이브러리\n",
        "y = np.empty((0, 1)) # 비어있는 리스트 만들기\n",
        "\n",
        "for f in X_path_new:\n",
        "    if 'ori' in ntpath.basename(f): #  음성 데이터가 있는 디렉토리의 데이터가 '원본' 음성 : 0\n",
        "        resp = np.array([0])  #   [0]\n",
        "    elif 'AI' in ntpath.basename(f): # 음성 데이터가 있는 디렉토리의 데이터가 'AI' 음성 : 1\n",
        "        resp = np.array([1])  # [1]\n",
        "    resp = resp.reshape(1, 1)\n",
        "    y = np.vstack((y, resp))\n",
        "print (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I0a_Z9cJ986w"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_path_new, y, test_size=0.25, random_state=42)\n",
        "print(len(X_train)) # 600\n",
        "print(len(X_test)) # 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jU3r03rL_wti"
      },
      "outputs": [],
      "source": [
        "# 첫 번째 파일의 샘플 레이트 확인\n",
        "sample_rate = librosa.load(X_train[0],sr = 16000)[1]\n",
        "print(sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lU1K8OpI-FrO"
      },
      "outputs": [],
      "source": [
        "# 음성파일 읽기 & 디지털 변환 함수\n",
        "def librosa_read_wav_files(wav_files):\n",
        "    if not isinstance(wav_files, list): # isinstance(1, int) # 1이 int형인지 알아본다. 결과는 True\n",
        "        wav_files = [wav_files]\n",
        "    return [librosa.load(f, sr = 16000)[0] for f in wav_files] # 음성파일 읽기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QojbepfI-Q2P"
      },
      "outputs": [],
      "source": [
        "# train/test 음성파일 읽기\n",
        "X_train2 = librosa_read_wav_files(X_train)\n",
        "X_test2  = librosa_read_wav_files(X_test)\n",
        "print(len(X_train2)) # 600\n",
        "print(len(X_test2)) # 200\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7w6DMHPm_FvG"
      },
      "outputs": [],
      "source": [
        "# 오디오 특징 추출 함수\n",
        "def extract_features(audio_samples, sample_rate):\n",
        "    extracted_features = np.empty((0, 101)) # (1,41) : 41개의 값을 받을 메모리를 할당하겠다는 뜻\n",
        "    if not isinstance(audio_samples, list):\n",
        "        audio_samples = [audio_samples]\n",
        "\n",
        "    for sample in audio_samples:\n",
        "        zero_cross_feat = librosa.feature.zero_crossing_rate(sample).mean()\n",
        "        mfccs = librosa.feature.mfcc(y=sample, sr=sample_rate, n_mfcc=100) # 오디오에서 40개 특징 추출\n",
        "        mfccsscaled = np.mean(mfccs.T,axis=0)  # 각 주파수별 평균값을 구하기\n",
        "        mfccsscaled = np.append(mfccsscaled, zero_cross_feat)\n",
        "        mfccsscaled = mfccsscaled.reshape(1, 101)\n",
        "        extracted_features = np.vstack((extracted_features, mfccsscaled))\n",
        "    return extracted_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OpVQJLpBAwfM"
      },
      "outputs": [],
      "source": [
        "# 오디오 특징 추출\n",
        "# wave_rate 에 사람음성에 속하는 주파수 영역을 주어야 한다.\n",
        "\n",
        "X_train_features = extract_features(X_train2, sample_rate) # wav_rate=22050(sample_rate)\n",
        "X_test_features  = extract_features(X_test2, sample_rate) # wav_rate=22050(sample_rate)\n",
        "print(X_train_features.shape) # (600, 101)\n",
        "print(X_test_features.shape) # (200, 101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PbNrTL7CBaFy"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "ayYKGhhLBcSP"
      },
      "outputs": [],
      "source": [
        "# 신경망 구축\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(101,1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(256, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WM5XpoZsB9VE"
      },
      "outputs": [],
      "source": [
        "# 학습환경\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VDc4d2LRt-1s"
      },
      "outputs": [],
      "source": [
        "# 여기서는 val_accuracy 모니터링해서 성능이 좋아지지 않으면 조기 종료 하게 함.\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "ujO0Tpmdt-9E"
      },
      "outputs": [],
      "source": [
        "check_point = ModelCheckpoint('best_model.h5', verbose=1,\n",
        "                              monitor='val_loss', save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "YZv4-WNgCjAL"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train_features, y_train, epochs=50, batch_size=32, validation_data=(X_test_features,y_test), verbose=1,\n",
        "          callbacks=[early_stop, check_point])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dgxpPxk9ICC5"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['acc','val_acc'])\n",
        "plt.title('Model ACC')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhmvLy9wfQ6p"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ofAH02fiK4Rd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}